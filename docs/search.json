[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am George Whittington\nAs an undergraduate student majoring in statistics, I‚Äôm particularly drawn to the exciting field of machine learning. I love the process of building models and seeing how they can solve real-world problems.\nI actively use both R and Python in my work, and I‚Äôm committed to transparency and collaboration by making my projects available on public repositories.\nIf I could describe myself using three emojis I would select: üëæ üòº üòÅ"
  },
  {
    "objectID": "models/datasets.html",
    "href": "models/datasets.html",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in class‚Ä¶\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/datasets.html#youth-risk-behavior-survey-2023",
    "href": "models/datasets.html#youth-risk-behavior-survey-2023",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in class‚Ä¶\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/lasso.html",
    "href": "models/lasso.html",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term ‚ÄúLasso‚Äù stands for ‚ÄúLeast Absolute Shrinkage and Selection Operator.‚Äù This method is particularly useful when dealing with datasets that have many predictors, as it helps to: - Reduce overfitting by penalizing large coefficients - Perform automatic feature selection by shrinking some coefficients to exactly zero - Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\nIn this analysis, we‚Äôll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability."
  },
  {
    "objectID": "models/lasso.html#setting-up-the-environment",
    "href": "models/lasso.html#setting-up-the-environment",
    "title": "Lasso Regression",
    "section": "Setting Up the Environment",
    "text": "Setting Up the Environment\nFirst, we need to load the necessary packages for our analysis. We‚Äôll use tidymodels for modeling, tidyverse for data manipulation, and here for consistent file paths.\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)"
  },
  {
    "objectID": "models/lasso.html#loading-the-data",
    "href": "models/lasso.html#loading-the-data",
    "title": "Lasso Regression",
    "section": "Loading the Data",
    "text": "Loading the Data\nWe‚Äôll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the processed_data directory.\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/lasso.html#data-preprocessing",
    "href": "models/lasso.html#data-preprocessing",
    "title": "Lasso Regression",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nBefore fitting our model, we need to preprocess the data. We‚Äôll create a recipe that: - Imputes missing values in categorical variables using the mode - Imputes missing values in numeric variables using the mean - Removes predictors with zero variance - Removes highly correlated predictors (correlation threshold = 0.7) - Creates dummy variables for categorical predictors\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) %&gt;% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n\n\n\n\n‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n\n‚îÄ‚îÄ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n‚îÄ‚îÄ Operations \n\n\n‚Ä¢ Mode imputation for: all_nominal_predictors()\n\n\n‚Ä¢ Mean imputation for: all_numeric_predictors()\n\n\n‚Ä¢ Zero variance filter on: all_predictors()\n\n\n‚Ä¢ Correlation filter on: all_numeric_predictors()\n\n\n‚Ä¢ Dummy variables from: all_nominal_predictors()\n\n\nLet‚Äôs apply our recipe to transform the data according to these preprocessing steps.\n\nweapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) \n\n# A tibble: 19,595 √ó 11\n   WeaponCarryingSchool AttackedInNeighborhood_X1 Bullying_X1\n   &lt;fct&gt;                                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 0                                            0           0\n 2 0                                            0           1\n 3 0                                            0           0\n 4 0                                            0           0\n 5 0                                            0           0\n 6 0                                            1           0\n 7 0                                            0           0\n 8 0                                            0           0\n 9 0                                            0           0\n10 0                                            0           0\n# ‚Ñπ 19,585 more rows\n# ‚Ñπ 8 more variables: SexualAbuseByOlderPerson_X1 &lt;dbl&gt;,\n#   ParentalPhysicalAbuse_X1 &lt;dbl&gt;, ParentSubstanceUse_X1 &lt;dbl&gt;,\n#   ParentIncarceration_X1 &lt;dbl&gt;, SchoolConnectedness_X1 &lt;dbl&gt;,\n#   ParentalMonitoring_X1 &lt;dbl&gt;, UnfairDisciplineAtSchool_X1 &lt;dbl&gt;,\n#   Homelessness_X1 &lt;dbl&gt;"
  },
  {
    "objectID": "models/lasso.html#model-specification",
    "href": "models/lasso.html#model-specification",
    "title": "Lasso Regression",
    "section": "Model Specification",
    "text": "Model Specification\nWe‚Äôll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set mixture = 1 to specify a pure Lasso model, and we‚Äôll tune the penalty parameter to find the optimal level of regularization.\n\nweapon_carry_spec &lt;-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |&gt; \n  set_engine('glmnet')\n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#creating-the-workflow",
    "href": "models/lasso.html#creating-the-workflow",
    "title": "Lasso Regression",
    "section": "Creating the Workflow",
    "text": "Creating the Workflow\nWe‚Äôll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\nweapon_carry_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(weapon_carry_recipe) |&gt;\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n5 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_zv()\n‚Ä¢ step_corr()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#model-tuning",
    "href": "models/lasso.html#model-tuning",
    "title": "Lasso Regression",
    "section": "Model Tuning",
    "text": "Model Tuning\nTo find the optimal penalty value, we‚Äôll create a grid of potential values to test. We‚Äôll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\nlambda_grid &lt;- grid_regular(penalty(), levels = 50)\nlambda_grid\n\n# A tibble: 50 √ó 1\n    penalty\n      &lt;dbl&gt;\n 1 1   e-10\n 2 1.60e-10\n 3 2.56e-10\n 4 4.09e-10\n 5 6.55e-10\n 6 1.05e- 9\n 7 1.68e- 9\n 8 2.68e- 9\n 9 4.29e- 9\n10 6.87e- 9\n# ‚Ñπ 40 more rows\n\n\nNow, we‚Äôll perform cross-validation to find the best penalty value. This process is time-consuming, so we‚Äôll save the results for future use.\n\nset.seed(2023)\n\nlasso_tune &lt;- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n\nLet‚Äôs examine the performance metrics for different penalty values.\n\nlasso_tune %&gt;% \n  collect_metrics()\n\n# A tibble: 150 √ó 7\n    penalty .metric     .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model01\n 2 1   e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model01\n 3 1   e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model01\n 4 1.60e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model02\n 5 1.60e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model02\n 6 1.60e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model02\n 7 2.56e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model03\n 8 2.56e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model03\n 9 2.56e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model03\n10 4.09e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model04\n# ‚Ñπ 140 more rows\n\n\nWe can visualize how the model‚Äôs performance changes with different penalty values.\n\nautoplot(lasso_tune)"
  },
  {
    "objectID": "models/lasso.html#selecting-the-best-model",
    "href": "models/lasso.html#selecting-the-best-model",
    "title": "Lasso Regression",
    "section": "Selecting the Best Model",
    "text": "Selecting the Best Model\nWe‚Äôll select the best model based on the ROC AUC metric, which measures the model‚Äôs ability to distinguish between classes.\n\nbest &lt;- lasso_tune |&gt; \n  select_best(metric =\"roc_auc\")\n\nbest\n\n# A tibble: 1 √ó 2\n   penalty .config              \n     &lt;dbl&gt; &lt;chr&gt;                \n1 0.000339 Preprocessor1_Model33\n\n\nNow we‚Äôll create our final workflow with the best penalty value.\n\nfinal_wf &lt;- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n5 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_zv()\n‚Ä¢ step_corr()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.000339322177189533\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#fitting-the-final-model",
    "href": "models/lasso.html#fitting-the-final-model",
    "title": "Lasso Regression",
    "section": "Fitting the Final Model",
    "text": "Fitting the Final Model\nWe‚Äôll fit our final model on the training data. This process is also time-consuming, so we‚Äôll save the results.\n\nweapon_fit &lt;- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit"
  },
  {
    "objectID": "models/lasso.html#model-evaluation",
    "href": "models/lasso.html#model-evaluation",
    "title": "Lasso Regression",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nLet‚Äôs examine the model‚Äôs predictions on the training data.\n\nweapon_pred &lt;- \n  augment(weapon_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 √ó 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0368   0.963\n 2 0                    0            0.0410   0.959\n 3 0                    0            0.0253   0.975\n 4 0                    0            0.0325   0.968\n 5 0                    0            0.125    0.875\n 6 0                    0            0.0368   0.963\n 7 0                    0            0.0208   0.979\n 8 0                    0            0.0208   0.979\n 9 0                    0            0.0458   0.954\n10 0                    0            0.0529   0.947\n# ‚Ñπ 14,686 more rows\n\n\nWe can visualize the model‚Äôs performance using an ROC curve.\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\nLet‚Äôs look at the model coefficients to understand which predictors are most important.\n\nweapon_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  tidy()\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-9\n\n\n# A tibble: 11 √ó 3\n   term                        estimate  penalty\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -3.29   0.000339\n 2 AttackedInNeighborhood_X1     0.739  0.000339\n 3 Bullying_X1                   0.472  0.000339\n 4 SexualAbuseByOlderPerson_X1   0.455  0.000339\n 5 ParentalPhysicalAbuse_X1      0.708  0.000339\n 6 ParentSubstanceUse_X1        -0.132  0.000339\n 7 ParentIncarceration_X1        0.0271 0.000339\n 8 SchoolConnectedness_X1       -0.226  0.000339\n 9 ParentalMonitoring_X1         0.584  0.000339\n10 UnfairDisciplineAtSchool_X1  -0.229  0.000339\n11 Homelessness_X1               1.17   0.000339"
  },
  {
    "objectID": "models/lasso.html#cross-validation-results",
    "href": "models/lasso.html#cross-validation-results",
    "title": "Lasso Regression",
    "section": "Cross-Validation Results",
    "text": "Cross-Validation Results\nWe‚Äôll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\nweapon_fit_resamples &lt;- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n\nLet‚Äôs examine the cross-validation metrics.\n\ncollect_metrics(weapon_fit_resamples)\n\n# A tibble: 3 √ó 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.957      5 0.00158 Preprocessor1_Model1\n2 brier_class binary     0.0399     5 0.00128 Preprocessor1_Model1\n3 roc_auc     binary     0.688      5 0.00737 Preprocessor1_Model1"
  },
  {
    "objectID": "models/lasso.html#variable-importance",
    "href": "models/lasso.html#variable-importance",
    "title": "Lasso Regression",
    "section": "Variable Importance",
    "text": "Variable Importance\nFinally, let‚Äôs create a variable importance plot to identify the most influential predictors in our model.\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nweapon_fit |&gt; \n  extract_fit_engine() |&gt; \n  vip()"
  },
  {
    "objectID": "models/lasso.html#results-and-interpretation",
    "href": "models/lasso.html#results-and-interpretation",
    "title": "Lasso Regression",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n[Add your interpretation of the results here]"
  },
  {
    "objectID": "models/logistic.html",
    "href": "models/logistic.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Logistic regression is a statistical model that‚Ä¶\n\nModel Overview\nLogistic regression is used when the dependent variable is binary (0/1, Yes/No, True/False). The model estimates the probability of the dependent variable being 1 given the independent variables.\n\n\nImplementation\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(dissertationData)\nlibrary(here)\n\n# Load and prepare the YRBS 2023 dataset\n\n\n\nLoad the data\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\", \"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n\n\nRecipe\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_data) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) \n\nweapon_carry_recipe\n\n\n\n\n‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n\n‚îÄ‚îÄ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n‚îÄ‚îÄ Operations \n\n\n‚Ä¢ Mode imputation for: all_nominal_predictors()\n\n\n‚Ä¢ Mean imputation for: all_numeric_predictors()\n\n\n‚Ä¢ Zero variance filter on: all_predictors()\n\n\n‚Ä¢ Correlation filter on: all_numeric_predictors()\n\n\n\n\nBake\n\nrec &lt;- weapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) %&gt;% glimpse()\n\nRows: 19,595\nColumns: 11\n$ AttackedInNeighborhood   &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ‚Ä¶\n$ Bullying                 &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ SexualAbuseByOlderPerson &lt;fct&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ‚Ä¶\n$ ParentalPhysicalAbuse    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ ParentSubstanceUse       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ‚Ä¶\n$ ParentIncarceration      &lt;fct&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ SchoolConnectedness      &lt;fct&gt; 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, ‚Ä¶\n$ ParentalMonitoring       &lt;fct&gt; 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, ‚Ä¶\n$ UnfairDisciplineAtSchool &lt;fct&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ Homelessness             &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ WeaponCarryingSchool     &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n\n\n\n\nModel Specification\n\nweapon_carry_spec &lt;- \n  logistic_reg() %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\") \n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nWorkflow\n\nweapon_carry_workflow &lt;- workflow() %&gt;%\n  add_recipe(weapon_carry_recipe) %&gt;%\n  add_model(weapon_carry_spec)\n\n\nweapon_carry_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n4 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_zv()\n‚Ä¢ step_corr()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\nmod_1 &lt;- \n  fit(weapon_carry_workflow, data = analysis_train) \n\nmod_1\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n4 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_zv()\n‚Ä¢ step_corr()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n              (Intercept)    AttackedInNeighborhood1  \n                 -3.29938                    0.74950  \n                Bullying1  SexualAbuseByOlderPerson1  \n                  0.48405                    0.46540  \n   ParentalPhysicalAbuse1        ParentSubstanceUse1  \n                  0.71713                   -0.15917  \n     ParentIncarceration1       SchoolConnectedness1  \n                  0.07048                   -0.25542  \n      ParentalMonitoring1  UnfairDisciplineAtSchool1  \n                  0.59860                   -0.24268  \n            Homelessness1  \n                  1.18053  \n\nDegrees of Freedom: 14695 Total (i.e. Null);  14685 Residual\nNull Deviance:      5238 \nResidual Deviance: 4872     AIC: 4894\n\n\n\ntidy_model &lt;- \n  mod_1 |&gt;\n  tidy(exponentiate = TRUE,\n       conf.int = TRUE, \n       conf.level = .95) |&gt;\n  mutate(p.value = scales::pvalue(p.value))\n\ntidy_model\n\n# A tibble: 11 √ó 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)             0.0369    0.166    -19.9   &lt;0.001    0.0266    0.0508\n 2 AttackedInNeighborho‚Ä¶   2.12      0.0954     7.85  &lt;0.001    1.75      2.55  \n 3 Bullying1               1.62      0.0919     5.27  &lt;0.001    1.35      1.94  \n 4 SexualAbuseByOlderPe‚Ä¶   1.59      0.133      3.51  &lt;0.001    1.22      2.06  \n 5 ParentalPhysicalAbus‚Ä¶   2.05      0.179      4.01  &lt;0.001    1.43      2.89  \n 6 ParentSubstanceUse1     0.853     0.111     -1.44  0.151     0.688     1.06  \n 7 ParentIncarceration1    1.07      0.126      0.560 0.575     0.841     1.38  \n 8 SchoolConnectedness1    0.775     0.0970    -2.63  0.008     0.639     0.935 \n 9 ParentalMonitoring1     1.82      0.114      5.26  &lt;0.001    1.45      2.27  \n10 UnfairDisciplineAtSc‚Ä¶   0.785     0.114     -2.13  0.033     0.629     0.984 \n11 Homelessness1           3.26      0.155      7.61  &lt;0.001    2.39      4.39  \n\n\n\n\nModel Evaluation\n\nweapon_pred &lt;- \n  augment(mod_1, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 √ó 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0360   0.964\n 2 0                    0            0.0412   0.959\n 3 0                    0            0.0241   0.976\n 4 0                    0            0.0317   0.968\n 5 0                    0            0.128    0.872\n 6 0                    0            0.0360   0.964\n 7 0                    0            0.0201   0.980\n 8 0                    0            0.0201   0.980\n 9 0                    0            0.0471   0.953\n10 0                    0            0.0531   0.947\n# ‚Ñπ 14,686 more rows\n\n\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\n\n\nVisualizations\n\ntidy_model |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate, y = reorder(term, estimate))) +\n  geom_point(size = 3) +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    x = \"Odds Ratio (log scale)\",\n    y = \"Predictors\",\n    title = \"Forest Plot of Logistic Regression Coefficients\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\nResults and Interpretation\n\n\nKey Takeaways"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Notebook üëÄ",
    "section": "",
    "text": "This website will be our Machine Learning course, where we explore various statistical and machine learning models using the Youth Risk Behavior Survey (YRBS) 2023 dataset. Through this course, I learned to implement and understand different modeling techniques using the tidymodels framework in R.\n\nWhat You‚Äôll Find Here\n\nAbout Me: A little bit about me and my research interests.\nThe Dataset: Information about my primary dataset and the research question I am trying to answer.\nModel Implementations: Hands-on examples of different models to answer the question:\n\nLogistic Regression\nLasso Regression\nDecision Trees\nRandom Forest\nK-Nearest Neighbors (KNN)"
  },
  {
    "objectID": "models/trees.html",
    "href": "models/trees.html",
    "title": "Classification Tree",
    "section": "",
    "text": "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes."
  },
  {
    "objectID": "models/trees.html#libraries",
    "href": "models/trees.html#libraries",
    "title": "Classification Tree",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(tidymodels)"
  },
  {
    "objectID": "models/trees.html#data",
    "href": "models/trees.html#data",
    "title": "Classification Tree",
    "section": "Data",
    "text": "Data\n\nanalysis_train &lt;- readRDS(\"data/analysis_train.rds\")\nanalysis_folds &lt;- readRDS(\"data/analysis_folds.rds\")"
  },
  {
    "objectID": "models/trees.html#model-recipe",
    "href": "models/trees.html#model-recipe",
    "title": "Classification Tree",
    "section": "Model Recipe",
    "text": "Model Recipe\n\ntree_recipe &lt;-\n  recipe(WeaponCarryingSchool ~ ., data = analysis_train) |&gt; \n  step_impute_mode(all_nominal_predictors()) |&gt; \n  step_impute_mean(all_numeric_predictors())\n\ntree_recipe\n\n\n\n\n‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n\n‚îÄ‚îÄ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n‚îÄ‚îÄ Operations \n\n\n‚Ä¢ Mode imputation for: all_nominal_predictors()\n\n\n‚Ä¢ Mean imputation for: all_numeric_predictors()"
  },
  {
    "objectID": "models/trees.html#model-specification",
    "href": "models/trees.html#model-specification",
    "title": "Classification Tree",
    "section": "Model Specification",
    "text": "Model Specification\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n  ) |&gt; \n  set_engine(\"rpart\") |&gt; \n  set_mode(\"classification\")\n\ntree_spec\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart"
  },
  {
    "objectID": "models/trees.html#model-workflow",
    "href": "models/trees.html#model-workflow",
    "title": "Classification Tree",
    "section": "Model Workflow",
    "text": "Model Workflow\n\ntree_workflow &lt;-\n  workflow() |&gt; \n  add_recipe(tree_recipe) |&gt; \n  add_model(tree_spec)\n\ntree_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: decision_tree()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart"
  },
  {
    "objectID": "models/trees.html#grid-search-cross-validation",
    "href": "models/trees.html#grid-search-cross-validation",
    "title": "Classification Tree",
    "section": "Grid Search Cross Validation",
    "text": "Grid Search Cross Validation\n\ntree_grid &lt;- grid_regular(\n  cost_complexity(),\n  tree_depth(c(2,5)),\n  min_n(),\n  levels = 2\n)\n\ntree_grid\n\n# A tibble: 8 √ó 3\n  cost_complexity tree_depth min_n\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n1    0.0000000001          2     2\n2    0.1                   2     2\n3    0.0000000001          5     2\n4    0.1                   5     2\n5    0.0000000001          2    40\n6    0.1                   2    40\n7    0.0000000001          5    40\n8    0.1                   5    40"
  },
  {
    "objectID": "models/trees.html#hyperparameter-tuning",
    "href": "models/trees.html#hyperparameter-tuning",
    "title": "Classification Tree",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\n\ntree_tune &lt;-\n  tree_workflow |&gt; \n  tune_grid(\n    resamples = analysis_folds,\n    grid = tree_grid,\n    metrics = metric_set(roc_auc),\n    control = control_grid(save_pred = TRUE)\n  )\n\nsaveRDS(tree_tune, \"model_outputs/tree_tune.rds\")\n\ntree_tune\n\n\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 √ó 5\n  splits               id    .metrics         .notes           .predictions\n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n1 &lt;split [11756/2940]&gt; Fold1 &lt;tibble [8 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; &lt;tibble&gt;    \n2 &lt;split [11757/2939]&gt; Fold2 &lt;tibble [8 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; &lt;tibble&gt;    \n3 &lt;split [11757/2939]&gt; Fold3 &lt;tibble [8 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; &lt;tibble&gt;    \n4 &lt;split [11757/2939]&gt; Fold4 &lt;tibble [8 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; &lt;tibble&gt;    \n5 &lt;split [11757/2939]&gt; Fold5 &lt;tibble [8 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; &lt;tibble&gt;    \n\n\n\nshow_best(tree_tune, metric = \"roc_auc\")\n\n# A tibble: 5 √ó 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          5     2 roc_auc binary     0.592     5 0.0226 \n2    0.0000000001          5    40 roc_auc binary     0.534     5 0.0167 \n3    0.0000000001          2     2 roc_auc binary     0.507     5 0.00740\n4    0.0000000001          2    40 roc_auc binary     0.507     5 0.00740\n5    0.1                   2     2 roc_auc binary     0.5       5 0      \n# ‚Ñπ 1 more variable: .config &lt;chr&gt;\n\n\n\nbest_plot_tree &lt;- autoplot(tree_tune)\n\nbest_plot_tree\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\n\nbest_tree &lt;- select_best(tree_tune, metric = \"roc_auc\")\n\nbest_tree\n\n# A tibble: 1 √ó 4\n  cost_complexity tree_depth min_n .config             \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1    0.0000000001          5     2 Preprocessor1_Model3"
  },
  {
    "objectID": "models/trees.html#finalize-model-workflow",
    "href": "models/trees.html#finalize-model-workflow",
    "title": "Classification Tree",
    "section": "Finalize Model Workflow",
    "text": "Finalize Model Workflow\n\ntree_final_workflow &lt;- finalize_workflow(tree_workflow, best_tree)\n\ntree_final_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: decision_tree()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 5\n  min_n = 2\n\nComputational engine: rpart"
  },
  {
    "objectID": "models/trees.html#fit-the-model",
    "href": "models/trees.html#fit-the-model",
    "title": "Classification Tree",
    "section": "Fit the Model",
    "text": "Fit the Model\n\ntree_fit &lt;- fit(tree_final_workflow, analysis_train)\n\nsaveRDS(tree_fit, \"model_outputs/tree_fit.rds\")\n\ntree_fit\n\n\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: decision_tree()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nn= 14696 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 14696 636 0 (0.95672292 0.04327708)  \n   2) Homelessness=0 14336 567 0 (0.96044922 0.03955078) *\n   3) Homelessness=1 360  69 0 (0.80833333 0.19166667)  \n     6) SexualAbuseByOlderPerson=0 298  45 0 (0.84899329 0.15100671)  \n      12) AttackedInNeighborhood=0 208  24 0 (0.88461538 0.11538462) *\n      13) AttackedInNeighborhood=1 90  21 0 (0.76666667 0.23333333)  \n        26) SchoolConnectedness=1 38   5 0 (0.86842105 0.13157895) *\n        27) SchoolConnectedness=0 52  16 0 (0.69230769 0.30769231)  \n          54) ParentalPhysicalAbuse=0 47  12 0 (0.74468085 0.25531915) *\n          55) ParentalPhysicalAbuse=1 5   1 1 (0.20000000 0.80000000) *\n     7) SexualAbuseByOlderPerson=1 62  24 0 (0.61290323 0.38709677)  \n      14) ParentIncarceration=1 30   8 0 (0.73333333 0.26666667) *\n      15) ParentIncarceration=0 32  16 0 (0.50000000 0.50000000)  \n        30) ParentalPhysicalAbuse=0 15   6 0 (0.60000000 0.40000000) *\n        31) ParentalPhysicalAbuse=1 17   7 1 (0.41176471 0.58823529)  \n          62) SchoolConnectedness=0 8   3 0 (0.62500000 0.37500000) *\n          63) SchoolConnectedness=1 9   2 1 (0.22222222 0.77777778) *"
  },
  {
    "objectID": "models/trees.html#make-model-predictions",
    "href": "models/trees.html#make-model-predictions",
    "title": "Classification Tree",
    "section": "Make Model Predictions",
    "text": "Make Model Predictions\n\ntree_pred &lt;- \n  augment(tree_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\ntree_pred\n\n# A tibble: 14,696 √ó 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0396   0.960\n 2 0                    0            0.0396   0.960\n 3 0                    0            0.0396   0.960\n 4 0                    0            0.0396   0.960\n 5 0                    0            0.0396   0.960\n 6 0                    0            0.0396   0.960\n 7 0                    0            0.0396   0.960\n 8 0                    0            0.0396   0.960\n 9 0                    0            0.0396   0.960\n10 0                    0            0.0396   0.960\n# ‚Ñπ 14,686 more rows"
  },
  {
    "objectID": "models/trees.html#roc-plot",
    "href": "models/trees.html#roc-plot",
    "title": "Classification Tree",
    "section": "ROC Plot",
    "text": "ROC Plot\n\nroc_tree &lt;- \n  tree_pred |&gt; \n  roc_curve(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  ) |&gt; \n  autoplot()\n\nsaveRDS(roc_tree, \"roc_graphs/tree.rds\")\n\nroc_tree\n\n\n\n\n\n\n\n\n\n\n\ntree_pred |&gt; \n  roc_auc(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  )\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.544"
  },
  {
    "objectID": "models/trees.html#resample-metrics",
    "href": "models/trees.html#resample-metrics",
    "title": "Classification Tree",
    "section": "Resample Metrics",
    "text": "Resample Metrics\n\nfit_resamples(tree_final_workflow, resamples = analysis_folds) |&gt; \n  collect_metrics()\n\n# A tibble: 3 √ó 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.955      5 0.00141 Preprocessor1_Model1\n2 brier_class binary     0.0412     5 0.00135 Preprocessor1_Model1\n3 roc_auc     binary     0.592      5 0.0226  Preprocessor1_Model1"
  },
  {
    "objectID": "models/trees.html#decision-tree-plots",
    "href": "models/trees.html#decision-tree-plots",
    "title": "Classification Tree",
    "section": "Decision Tree Plots",
    "text": "Decision Tree Plots\n\ntree_fit |&gt; \n  extract_fit_engine() |&gt; \n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\nFigure¬†2"
  },
  {
    "objectID": "models/trees.html#model-overview",
    "href": "models/trees.html#model-overview",
    "title": "Classification Tree",
    "section": "",
    "text": "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes."
  },
  {
    "objectID": "models/random-forest.html",
    "href": "models/random-forest.html",
    "title": "random-forest",
    "section": "",
    "text": "Random forest is a commonly-used machine learning algorithm, trademarked by Leo Breiman and Adele Cutler, that combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fueled its adoption, as it handles both classification and regression problems."
  },
  {
    "objectID": "models/random-forest.html#model-overview",
    "href": "models/random-forest.html#model-overview",
    "title": "random-forest",
    "section": "",
    "text": "Random forest is a commonly-used machine learning algorithm, trademarked by Leo Breiman and Adele Cutler, that combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fueled its adoption, as it handles both classification and regression problems."
  },
  {
    "objectID": "models/random-forest.html#libraries",
    "href": "models/random-forest.html#libraries",
    "title": "random-forest",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(tidymodels)"
  },
  {
    "objectID": "models/random-forest.html#data",
    "href": "models/random-forest.html#data",
    "title": "random-forest",
    "section": "Data",
    "text": "Data\n\nanalysis_train &lt;- readRDS(\"data/analysis_train.rds\")\nanalysis_folds &lt;- readRDS(\"data/analysis_folds.rds\")"
  },
  {
    "objectID": "models/random-forest.html#model-recipe",
    "href": "models/random-forest.html#model-recipe",
    "title": "random-forest",
    "section": "Model Recipe",
    "text": "Model Recipe\n\nforest_recipe &lt;-\n  recipe(WeaponCarryingSchool ~ ., data = analysis_train) |&gt; \n  step_impute_mode(all_nominal_predictors()) |&gt; \n  step_impute_mean(all_numeric_predictors()) |&gt; \n  step_dummy(all_nominal_predictors())\n\nforest_recipe\n\n\n\n\n‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n\n\n‚îÄ‚îÄ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n‚îÄ‚îÄ Operations \n\n\n‚Ä¢ Mode imputation for: all_nominal_predictors()\n\n\n‚Ä¢ Mean imputation for: all_numeric_predictors()\n\n\n‚Ä¢ Dummy variables from: all_nominal_predictors()"
  },
  {
    "objectID": "models/random-forest.html#model-specification",
    "href": "models/random-forest.html#model-specification",
    "title": "random-forest",
    "section": "Model Specification",
    "text": "Model Specification\n\nforest_spec &lt;- \n  rand_forest(\n    mtry = tune(),\n    min_n = tune(),\n    trees = 100\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\nforest_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#model-workflow",
    "href": "models/random-forest.html#model-workflow",
    "title": "random-forest",
    "section": "Model Workflow",
    "text": "Model Workflow\n\nforest_workflow &lt;-\n  workflow() |&gt; \n  add_recipe(forest_recipe) |&gt; \n  add_model(forest_spec)\n\nforest_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n3 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#hyperparameter-tuning",
    "href": "models/random-forest.html#hyperparameter-tuning",
    "title": "random-forest",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\n\nforest_tune &lt;-\n  tune_grid(\n    forest_workflow,\n    resamples = analysis_folds,\n    grid = 11\n  )\n\nsaveRDS(forest_tune, \"model_outputs/forest_tune.rds\")\n\nforest_tune\n\n\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 √ó 4\n  splits               id    .metrics          .notes          \n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [11756/2940]&gt; Fold1 &lt;tibble [33 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n2 &lt;split [11757/2939]&gt; Fold2 &lt;tibble [33 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n3 &lt;split [11757/2939]&gt; Fold3 &lt;tibble [33 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n4 &lt;split [11757/2939]&gt; Fold4 &lt;tibble [33 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n5 &lt;split [11757/2939]&gt; Fold5 &lt;tibble [33 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;"
  },
  {
    "objectID": "models/random-forest.html#collect-tuning-metrics",
    "href": "models/random-forest.html#collect-tuning-metrics",
    "title": "random-forest",
    "section": "Collect Tuning Metrics",
    "text": "Collect Tuning Metrics\n\ncollect_metrics(forest_tune)\n\n# A tibble: 33 √ó 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0402     5 0.00125 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.685      5 0.0100  Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0402     5 0.00125 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.682      5 0.00940 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.957      5 0.00137 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0400     5 0.00124 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.683      5 0.0100  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.957      5 0.00140 Preprocessor1_Model04\n# ‚Ñπ 23 more rows"
  },
  {
    "objectID": "models/random-forest.html#visualize-metrics",
    "href": "models/random-forest.html#visualize-metrics",
    "title": "random-forest",
    "section": "Visualize Metrics",
    "text": "Visualize Metrics\n\nautoplot(forest_tune)\n\n\n\n\n\n\n\n\n\nbest_forest &lt;- select_best(forest_tune, metric = \"roc_auc\")\n\nbest_forest\n\n# A tibble: 1 √ó 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    17 Preprocessor1_Model01"
  },
  {
    "objectID": "models/random-forest.html#finalize-model-workflow",
    "href": "models/random-forest.html#finalize-model-workflow",
    "title": "random-forest",
    "section": "Finalize Model Workflow",
    "text": "Finalize Model Workflow\n\nforest_final_workflow &lt;- finalize_workflow(forest_workflow, best_forest)\n\nforest_final_workflow\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n3 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#fit-the-model",
    "href": "models/random-forest.html#fit-the-model",
    "title": "random-forest",
    "section": "Fit the Model",
    "text": "Fit the Model\n\nforest_fit &lt;- fit(forest_final_workflow, analysis_train)\n\nsaveRDS(forest_fit, \"model_outputs/forest_fit.rds\")\n\nforest_fit\n\n\n\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n3 Recipe Steps\n\n‚Ä¢ step_impute_mode()\n‚Ä¢ step_impute_mean()\n‚Ä¢ step_dummy()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n$predictions\n                 0          1\n    [1,] 0.9608257 0.03917430\n    [2,] 0.9568533 0.04314667\n    [3,] 0.9651574 0.03484262\n    [4,] 0.9609997 0.03900031\n    [5,] 0.8917902 0.10820980\n    [6,] 0.9597347 0.04026534\n    [7,] 0.9686024 0.03139763\n    [8,] 0.9689044 0.03109564\n    [9,] 0.9456051 0.05439494\n   [10,] 0.9474776 0.05252242\n   [11,] 0.9529758 0.04702418\n   [12,] 0.9703308 0.02966922\n   [13,] 0.9440026 0.05599735\n   [14,] 0.9640737 0.03592628\n   [15,] 0.9307460 0.06925404\n   [16,] 0.9513482 0.04865182\n   [17,] 0.9378970 0.06210295\n   [18,] 0.9650748 0.03492525\n   [19,] 0.9615630 0.03843704\n   [20,] 0.9547721 0.04522794\n   [21,] 0.9679067 0.03209330\n   [22,] 0.9694196 0.03058044\n   [23,] 0.9306889 0.06931114\n   [24,] 0.9556499 0.04435009\n   [25,] 0.9497248 0.05027516\n   [26,] 0.9694189 0.03058112\n   [27,] 0.9694646 0.03053542\n   [28,] 0.9550579 0.04494215\n   [29,] 0.8869398 0.11306018\n   [30,] 0.9477009 0.05229912\n   [31,] 0.9497483 0.05025172\n   [32,] 0.9698491 0.03015094\n   [33,] 0.9693925 0.03060747\n   [34,] 0.9700790 0.02992103\n   [35,] 0.9703145 0.02968552\n   [36,] 0.9577626 0.04223742\n   [37,] 0.9706744 0.02932564\n   [38,] 0.9672956 0.03270444\n   [39,] 0.9573243 0.04267572\n   [40,] 0.9622386 0.03776138\n   [41,] 0.9649167 0.03508327\n   [42,] 0.9697737 0.03022634\n   [43,] 0.9541836 0.04581642\n   [44,] 0.9553624 0.04463762\n   [45,] 0.9683648 0.03163522\n   [46,] 0.9696704 0.03032959\n   [47,] 0.9687350 0.03126499\n   [48,] 0.9702012 0.02979883\n\n...\nand 30337 more lines."
  },
  {
    "objectID": "models/random-forest.html#make-model-predictions",
    "href": "models/random-forest.html#make-model-predictions",
    "title": "random-forest",
    "section": "Make Model Predictions",
    "text": "Make Model Predictions\n\nforest_pred &lt;- \n  augment(forest_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nforest_pred\n\n# A tibble: 14,696 √ó 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0456   0.954\n 2 0                    0            0.0430   0.957\n 3 0                    0            0.0329   0.967\n 4 0                    0            0.0394   0.961\n 5 0                    0            0.109    0.891\n 6 0                    0            0.0456   0.954\n 7 0                    0            0.0308   0.969\n 8 0                    0            0.0308   0.969\n 9 0                    0            0.0512   0.949\n10 0                    0            0.0487   0.951\n# ‚Ñπ 14,686 more rows"
  },
  {
    "objectID": "models/random-forest.html#roc-plot",
    "href": "models/random-forest.html#roc-plot",
    "title": "random-forest",
    "section": "ROC Plot",
    "text": "ROC Plot\n\nroc_forest &lt;- \n  forest_pred |&gt; \n  roc_curve(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  ) |&gt; \n  autoplot()\n\nsaveRDS(roc_forest, \"roc_graphs/forest.rds\")\n\nroc_forest\n\n\n\n\n\n\n\n\n\n\n\nforest_pred |&gt; \n  roc_auc(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  )\n\n# A tibble: 1 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.693"
  },
  {
    "objectID": "models/random-forest.html#resample-metrics",
    "href": "models/random-forest.html#resample-metrics",
    "title": "random-forest",
    "section": "Resample Metrics",
    "text": "Resample Metrics\n\nfit_resamples(forest_final_workflow, resamples = analysis_folds) |&gt; \n  collect_metrics()\n\n# A tibble: 3 √ó 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model1\n2 brier_class binary     0.0402     5 0.00126 Preprocessor1_Model1\n3 roc_auc     binary     0.686      5 0.0102  Preprocessor1_Model1"
  }
]
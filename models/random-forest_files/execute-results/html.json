{
  "hash": "31346b64fae748171ace4d8314a269d2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"random-forest\"\nformat: \n  html: \n    embed-resources: true\n---\n\n## Model Overview\n\nRandom forest is a commonly-used machine learning algorithm, trademarked by Leo Breiman and Adele Cutler, that combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fueled its adoption, as it handles both classification and regression problems.\n\n## Libraries\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n:::\n\n\n## Data\n\n::: {.cell}\n\n```{.r .cell-code}\nanalysis_train <- readRDS(\"data/analysis_train.rds\")\nanalysis_folds <- readRDS(\"data/analysis_folds.rds\")\n```\n:::\n\n\n\n\n## Model Recipe\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_recipe <-\n  recipe(WeaponCarryingSchool ~ ., data = analysis_train) |> \n  step_impute_mode(all_nominal_predictors()) |> \n  step_impute_mean(all_numeric_predictors()) |> \n  step_dummy(all_nominal_predictors())\n\nforest_recipe\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Inputs \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of variables by role\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\noutcome:    1\npredictor: 10\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Operations \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Mode imputation for: all_nominal_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Mean imputation for: all_numeric_predictors()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Dummy variables from: all_nominal_predictors()\n```\n\n\n:::\n:::\n\n\n## Model Specification\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_spec <- \n  rand_forest(\n    mtry = tune(),\n    min_n = tune(),\n    trees = 100\n  ) |> \n  set_mode(\"classification\") |> \n  set_engine(\"ranger\", importance = \"permutation\")\n\nforest_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n## Model Workflow\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_workflow <-\n  workflow() |> \n  add_recipe(forest_recipe) |> \n  add_model(forest_spec)\n\nforest_workflow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n## Hyperparameter Tuning\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_tune <-\n  tune_grid(\n    forest_workflow,\n    resamples = analysis_folds,\n    grid = 11\n  )\n\nsaveRDS(forest_tune, \"model_outputs/forest_tune.rds\")\n\nforest_tune\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits               id    .metrics          .notes          \n  <list>               <chr> <list>            <list>          \n1 <split [11756/2940]> Fold1 <tibble [33 × 6]> <tibble [0 × 3]>\n2 <split [11757/2939]> Fold2 <tibble [33 × 6]> <tibble [0 × 3]>\n3 <split [11757/2939]> Fold3 <tibble [33 × 6]> <tibble [0 × 3]>\n4 <split [11757/2939]> Fold4 <tibble [33 × 6]> <tibble [0 × 3]>\n5 <split [11757/2939]> Fold5 <tibble [33 × 6]> <tibble [0 × 3]>\n```\n\n\n:::\n:::\n\n\n## Collect Tuning Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(forest_tune)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 33 × 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   <int> <int> <chr>       <chr>       <dbl> <int>   <dbl> <chr>                \n 1     1    17 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0402     5 0.00125 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.685      5 0.0100  Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0402     5 0.00125 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.682      5 0.00940 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.957      5 0.00137 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0400     5 0.00124 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.683      5 0.0100  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.957      5 0.00140 Preprocessor1_Model04\n# ℹ 23 more rows\n```\n\n\n:::\n:::\n\n\n## Visualize Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(forest_tune)\n```\n\n::: {.cell-output-display}\n![](random-forest_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_forest <- select_best(forest_tune, metric = \"roc_auc\")\n\nbest_forest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     1    17 Preprocessor1_Model01\n```\n\n\n:::\n:::\n\n\n## Finalize Model Workflow\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_final_workflow <- finalize_workflow(forest_workflow, best_forest)\n\nforest_final_workflow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n## Fit the Model\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_fit <- fit(forest_final_workflow, analysis_train)\n\nsaveRDS(forest_fit, \"model_outputs/forest_fit.rds\")\n\nforest_fit\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n$predictions\n                 0          1\n    [1,] 0.9608257 0.03917430\n    [2,] 0.9568533 0.04314667\n    [3,] 0.9651574 0.03484262\n    [4,] 0.9609997 0.03900031\n    [5,] 0.8917902 0.10820980\n    [6,] 0.9597347 0.04026534\n    [7,] 0.9686024 0.03139763\n    [8,] 0.9689044 0.03109564\n    [9,] 0.9456051 0.05439494\n   [10,] 0.9474776 0.05252242\n   [11,] 0.9529758 0.04702418\n   [12,] 0.9703308 0.02966922\n   [13,] 0.9440026 0.05599735\n   [14,] 0.9640737 0.03592628\n   [15,] 0.9307460 0.06925404\n   [16,] 0.9513482 0.04865182\n   [17,] 0.9378970 0.06210295\n   [18,] 0.9650748 0.03492525\n   [19,] 0.9615630 0.03843704\n   [20,] 0.9547721 0.04522794\n   [21,] 0.9679067 0.03209330\n   [22,] 0.9694196 0.03058044\n   [23,] 0.9306889 0.06931114\n   [24,] 0.9556499 0.04435009\n   [25,] 0.9497248 0.05027516\n   [26,] 0.9694189 0.03058112\n   [27,] 0.9694646 0.03053542\n   [28,] 0.9550579 0.04494215\n   [29,] 0.8869398 0.11306018\n   [30,] 0.9477009 0.05229912\n   [31,] 0.9497483 0.05025172\n   [32,] 0.9698491 0.03015094\n   [33,] 0.9693925 0.03060747\n   [34,] 0.9700790 0.02992103\n   [35,] 0.9703145 0.02968552\n   [36,] 0.9577626 0.04223742\n   [37,] 0.9706744 0.02932564\n   [38,] 0.9672956 0.03270444\n   [39,] 0.9573243 0.04267572\n   [40,] 0.9622386 0.03776138\n   [41,] 0.9649167 0.03508327\n   [42,] 0.9697737 0.03022634\n   [43,] 0.9541836 0.04581642\n   [44,] 0.9553624 0.04463762\n   [45,] 0.9683648 0.03163522\n   [46,] 0.9696704 0.03032959\n   [47,] 0.9687350 0.03126499\n   [48,] 0.9702012 0.02979883\n\n...\nand 30337 more lines.\n```\n\n\n:::\n:::\n\n\n## Make Model Predictions\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_pred <- \n  augment(forest_fit, analysis_train) |> \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nforest_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14,696 × 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   <fct>                <fct>         <dbl>   <dbl>\n 1 0                    0            0.0456   0.954\n 2 0                    0            0.0430   0.957\n 3 0                    0            0.0329   0.967\n 4 0                    0            0.0394   0.961\n 5 0                    0            0.109    0.891\n 6 0                    0            0.0456   0.954\n 7 0                    0            0.0308   0.969\n 8 0                    0            0.0308   0.969\n 9 0                    0            0.0512   0.949\n10 0                    0            0.0487   0.951\n# ℹ 14,686 more rows\n```\n\n\n:::\n:::\n\n\n## ROC Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nroc_forest <- \n  forest_pred |> \n  roc_curve(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  ) |> \n  autoplot()\n\nsaveRDS(roc_forest, \"roc_graphs/forest.rds\")\n\nroc_forest\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](random-forest_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforest_pred |> \n  roc_auc(\n    truth = WeaponCarryingSchool,\n    .pred_1,\n    event_level = \"second\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.693\n```\n\n\n:::\n:::\n\n\n## Resample Metrics\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_resamples(forest_final_workflow, resamples = analysis_folds) |> \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  .metric     .estimator   mean     n std_err .config             \n  <chr>       <chr>       <dbl> <int>   <dbl> <chr>               \n1 accuracy    binary     0.957      5 0.00142 Preprocessor1_Model1\n2 brier_class binary     0.0402     5 0.00126 Preprocessor1_Model1\n3 roc_auc     binary     0.686      5 0.0102  Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n",
    "supporting": [
      "random-forest_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}